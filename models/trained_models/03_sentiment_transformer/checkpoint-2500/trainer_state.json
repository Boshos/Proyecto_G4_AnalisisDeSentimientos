{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8333333333333334,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016666666666666666,
      "grad_norm": 3.115821599960327,
      "learning_rate": 2.9836666666666665e-05,
      "loss": 1.0706,
      "step": 50
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 1.608338713645935,
      "learning_rate": 2.967e-05,
      "loss": 1.0693,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9303350448608398,
      "learning_rate": 2.9503333333333336e-05,
      "loss": 1.0678,
      "step": 150
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 4.235202312469482,
      "learning_rate": 2.933666666666667e-05,
      "loss": 1.0768,
      "step": 200
    },
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 3.545532703399658,
      "learning_rate": 2.9170000000000004e-05,
      "loss": 1.0737,
      "step": 250
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.185041666030884,
      "learning_rate": 2.9003333333333334e-05,
      "loss": 1.075,
      "step": 300
    },
    {
      "epoch": 0.11666666666666667,
      "grad_norm": 3.335514783859253,
      "learning_rate": 2.8836666666666668e-05,
      "loss": 1.0767,
      "step": 350
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 3.373791217803955,
      "learning_rate": 2.867e-05,
      "loss": 1.0696,
      "step": 400
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8721890449523926,
      "learning_rate": 2.8503333333333335e-05,
      "loss": 1.0818,
      "step": 450
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 1.672345519065857,
      "learning_rate": 2.833666666666667e-05,
      "loss": 1.0768,
      "step": 500
    },
    {
      "epoch": 0.18333333333333332,
      "grad_norm": 4.299988269805908,
      "learning_rate": 2.817e-05,
      "loss": 1.075,
      "step": 550
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6576850414276123,
      "learning_rate": 2.8003333333333333e-05,
      "loss": 1.088,
      "step": 600
    },
    {
      "epoch": 0.21666666666666667,
      "grad_norm": 3.133028268814087,
      "learning_rate": 2.7836666666666667e-05,
      "loss": 1.0793,
      "step": 650
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 1.9704374074935913,
      "learning_rate": 2.767e-05,
      "loss": 1.0857,
      "step": 700
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3103128671646118,
      "learning_rate": 2.7503333333333335e-05,
      "loss": 1.0677,
      "step": 750
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 2.716714859008789,
      "learning_rate": 2.733666666666667e-05,
      "loss": 1.0678,
      "step": 800
    },
    {
      "epoch": 0.2833333333333333,
      "grad_norm": 2.3759963512420654,
      "learning_rate": 2.717e-05,
      "loss": 1.071,
      "step": 850
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5315606594085693,
      "learning_rate": 2.7003333333333333e-05,
      "loss": 1.0699,
      "step": 900
    },
    {
      "epoch": 0.31666666666666665,
      "grad_norm": 1.4586771726608276,
      "learning_rate": 2.6836666666666667e-05,
      "loss": 1.0697,
      "step": 950
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 3.5174386501312256,
      "learning_rate": 2.667e-05,
      "loss": 1.0635,
      "step": 1000
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.3450117111206055,
      "learning_rate": 2.6503333333333334e-05,
      "loss": 1.0735,
      "step": 1050
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 2.623202323913574,
      "learning_rate": 2.6336666666666668e-05,
      "loss": 1.0752,
      "step": 1100
    },
    {
      "epoch": 0.38333333333333336,
      "grad_norm": 2.063809394836426,
      "learning_rate": 2.617e-05,
      "loss": 1.0628,
      "step": 1150
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.4334020614624023,
      "learning_rate": 2.6003333333333332e-05,
      "loss": 1.0714,
      "step": 1200
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 2.5566399097442627,
      "learning_rate": 2.5836666666666666e-05,
      "loss": 1.0757,
      "step": 1250
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 2.663787364959717,
      "learning_rate": 2.567e-05,
      "loss": 1.0792,
      "step": 1300
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.7536184787750244,
      "learning_rate": 2.5503333333333334e-05,
      "loss": 1.0709,
      "step": 1350
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 2.4514963626861572,
      "learning_rate": 2.5336666666666664e-05,
      "loss": 1.0721,
      "step": 1400
    },
    {
      "epoch": 0.48333333333333334,
      "grad_norm": 1.599787950515747,
      "learning_rate": 2.517e-05,
      "loss": 1.0682,
      "step": 1450
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7431048154830933,
      "learning_rate": 2.5003333333333335e-05,
      "loss": 1.0795,
      "step": 1500
    },
    {
      "epoch": 0.5166666666666667,
      "grad_norm": 2.0197300910949707,
      "learning_rate": 2.483666666666667e-05,
      "loss": 1.0757,
      "step": 1550
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.4598742723464966,
      "learning_rate": 2.4670000000000003e-05,
      "loss": 1.0676,
      "step": 1600
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9365025758743286,
      "learning_rate": 2.4503333333333336e-05,
      "loss": 1.0643,
      "step": 1650
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 2.8979198932647705,
      "learning_rate": 2.4336666666666667e-05,
      "loss": 1.0739,
      "step": 1700
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 2.1364498138427734,
      "learning_rate": 2.417e-05,
      "loss": 1.0524,
      "step": 1750
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9569013118743896,
      "learning_rate": 2.4003333333333334e-05,
      "loss": 1.0751,
      "step": 1800
    },
    {
      "epoch": 0.6166666666666667,
      "grad_norm": 2.5429177284240723,
      "learning_rate": 2.3836666666666668e-05,
      "loss": 1.065,
      "step": 1850
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 2.740353584289551,
      "learning_rate": 2.3670000000000002e-05,
      "loss": 1.0707,
      "step": 1900
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6796435117721558,
      "learning_rate": 2.3503333333333336e-05,
      "loss": 1.0717,
      "step": 1950
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.0931904315948486,
      "learning_rate": 2.3336666666666666e-05,
      "loss": 1.0658,
      "step": 2000
    },
    {
      "epoch": 0.6833333333333333,
      "grad_norm": 2.539318561553955,
      "learning_rate": 2.317e-05,
      "loss": 1.0643,
      "step": 2050
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.592773675918579,
      "learning_rate": 2.3003333333333334e-05,
      "loss": 1.0713,
      "step": 2100
    },
    {
      "epoch": 0.7166666666666667,
      "grad_norm": 3.856304883956909,
      "learning_rate": 2.2836666666666668e-05,
      "loss": 1.0647,
      "step": 2150
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 2.4438765048980713,
      "learning_rate": 2.267e-05,
      "loss": 1.069,
      "step": 2200
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.4549388885498047,
      "learning_rate": 2.2503333333333332e-05,
      "loss": 1.0782,
      "step": 2250
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 2.3395016193389893,
      "learning_rate": 2.2336666666666666e-05,
      "loss": 1.0641,
      "step": 2300
    },
    {
      "epoch": 0.7833333333333333,
      "grad_norm": 1.4156253337860107,
      "learning_rate": 2.217e-05,
      "loss": 1.0718,
      "step": 2350
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.500247001647949,
      "learning_rate": 2.2003333333333333e-05,
      "loss": 1.0722,
      "step": 2400
    },
    {
      "epoch": 0.8166666666666667,
      "grad_norm": 1.9317195415496826,
      "learning_rate": 2.1836666666666667e-05,
      "loss": 1.068,
      "step": 2450
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1.6220333576202393,
      "learning_rate": 2.167e-05,
      "loss": 1.0694,
      "step": 2500
    }
  ],
  "logging_steps": 50,
  "max_steps": 9000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6215195342928.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
